{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lung_hus.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "POlMOjtWN4KD",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": "OK"
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 46
        },
        "outputId": "7015c9bf-bff4-4b4c-af96-024cb98ff17e"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "df_node = pd.read_csv(io.BytesIO(uploaded['annotations.csv']))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-aada67ac-d54c-40ce-a31a-077467110d82\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-aada67ac-d54c-40ce-a31a-077467110d82\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yFyUuVZOK_pO",
        "outputId": "cbb57917-a009-491e-b852-fc561b6f66b3"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WtQ48szABIrJ"
      },
      "source": [
        "lung_folder = '/content/drive/MyDrive/lung/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F6XOfvYAYJcc",
        "outputId": "5dcdf6cb-9be2-41c5-9a73-9ae115063322"
      },
      "source": [
        "!ls \"/content/drive/My Drive/lung\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "kaggle\tluna2016  luna_subset  lung_subset\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eqn_4et6Yxdf",
        "outputId": "8966a6b3-6f41-4f8d-f029-f143a04aa62b"
      },
      "source": [
        "!pip install pydicom"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pydicom\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f4/15/df16546bc59bfca390cf072d473fb2c8acd4231636f64356593a63137e55/pydicom-2.1.2-py3-none-any.whl (1.9MB)\n",
            "\u001b[K     |████████████████████████████████| 1.9MB 5.7MB/s \n",
            "\u001b[?25hInstalling collected packages: pydicom\n",
            "Successfully installed pydicom-2.1.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "plsVEfj-hVMX",
        "outputId": "59bd906a-f699-4cd8-eaf4-5cae90c13eb8"
      },
      "source": [
        "!pip install SimpleITK"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting SimpleITK\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cc/85/6a7ce61f07cdaca722dd64f028b5678fb0a9e1bf66f534c2f8dd2eb78490/SimpleITK-2.0.2-cp36-cp36m-manylinux2010_x86_64.whl (47.4MB)\n",
            "\u001b[K     |████████████████████████████████| 47.4MB 94kB/s \n",
            "\u001b[?25hInstalling collected packages: SimpleITK\n",
            "Successfully installed SimpleITK-2.0.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4bwsJgznkm3d"
      },
      "source": [
        "# preprocessing\n",
        "\n",
        "import pydicom as dicom\n",
        "import os\n",
        "import numpy as np\n",
        "import scipy.ndimage\n",
        "from skimage import measure, morphology\n",
        "from mpl_toolkits.mplot3d.art3d import Poly3DCollection\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# Load the scans in given folder path\n",
        "def load_scan(path):\n",
        "    slices = [dicom.read_file(path + '/' + s) for s in os.listdir(path)]\n",
        "    slices.sort(key = lambda x: float(x.ImagePositionPatient[2]))\n",
        "    try:\n",
        "        slice_thickness = np.abs(slices[0].ImagePositionPatient[2] - slices[1].ImagePositionPatient[2])\n",
        "    except:\n",
        "        slice_thickness = np.abs(slices[0].SliceLocation - slices[1].SliceLocation)\n",
        "        \n",
        "    for s in slices:\n",
        "        s.SliceThickness = slice_thickness\n",
        "    return slices\n",
        "\n",
        "def get_pixels_hu(slices):\n",
        "    image = np.stack([s.pixel_array for s in slices])\n",
        "    # Convert to int16 (from sometimes int16), \n",
        "    # should be possible as values should always be low enough (<32k)\n",
        "    image = image.astype(np.int16)\n",
        "\n",
        "    # Set outside-of-scan pixels to 0\n",
        "    # The intercept is usually -1024, so air is approximately 0\n",
        "    image[image == -2000] = 0\n",
        "    \n",
        "    # Convert to Hounsfield units (HU)\n",
        "    for slice_number in range(len(slices)):\n",
        "        \n",
        "        intercept = slices[slice_number].RescaleIntercept\n",
        "        slope = slices[slice_number].RescaleSlope\n",
        "        \n",
        "        if slope != 1:\n",
        "            image[slice_number] = slope * image[slice_number].astype(np.float64)\n",
        "            image[slice_number] = image[slice_number].astype(np.int16)\n",
        "            \n",
        "        image[slice_number] += np.int16(intercept)\n",
        "    \n",
        "    return np.array(image, dtype=np.int16)\n",
        "\n",
        "def resample(image, scan, new_spacing=[1,1,1]):\n",
        "    # Determine current pixel spacing\n",
        "    spacing = np.array([scan[0].SliceThickness] + scan[0].PixelSpacing, dtype=np.float32)\n",
        "\n",
        "    resize_factor = spacing / new_spacing\n",
        "    new_real_shape = image.shape * resize_factor\n",
        "    new_shape = np.round(new_real_shape)\n",
        "    real_resize_factor = new_shape / image.shape\n",
        "    new_spacing = spacing / real_resize_factor\n",
        "    \n",
        "    image = scipy.ndimage.interpolation.zoom(image, real_resize_factor, mode='nearest')\n",
        "    \n",
        "    return image, new_spacing\n",
        "\n",
        "def plot_3d(image, threshold=-300):\n",
        "    \n",
        "    # Position the scan upright, \n",
        "    # so the head of the patient would be at the top facing the camera\n",
        "    p = image.transpose(2,1,0)\n",
        "    \n",
        "    verts, faces = measure.marching_cubes(p, threshold)\n",
        "\n",
        "    fig = plt.figure(figsize=(10, 10))\n",
        "    ax = fig.add_subplot(111, projection='3d')\n",
        "\n",
        "    # Fancy indexing: `verts[faces]` to generate a collection of triangles\n",
        "    mesh = Poly3DCollection(verts[faces], alpha=0.70)\n",
        "    face_color = [0.45, 0.45, 0.75]\n",
        "    mesh.set_facecolor(face_color)\n",
        "    ax.add_collection3d(mesh)\n",
        "\n",
        "    ax.set_xlim(0, p.shape[0])\n",
        "    ax.set_ylim(0, p.shape[1])\n",
        "    ax.set_zlim(0, p.shape[2])\n",
        "\n",
        "    plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bGsimM38kqTX"
      },
      "source": [
        "# imagenet_utils\n",
        "\n",
        "import numpy as np\n",
        "import json\n",
        "\n",
        "from keras.utils.data_utils import get_file\n",
        "from keras import backend as K\n",
        "\n",
        "CLASS_INDEX = None\n",
        "CLASS_INDEX_PATH = 'https://s3.amazonaws.com/deep-learning-models/image-models/imagenet_class_index.json'\n",
        "\n",
        "\n",
        "def preprocess_input(x, dim_ordering='default'):\n",
        "    if dim_ordering == 'default':\n",
        "        dim_ordering = K.image_dim_ordering()\n",
        "    assert dim_ordering in {'tf', 'th'}\n",
        "\n",
        "    if dim_ordering == 'th':\n",
        "        x[:, 0, :, :] -= 103.939\n",
        "        x[:, 1, :, :] -= 116.779\n",
        "        x[:, 2, :, :] -= 123.68\n",
        "        # 'RGB'->'BGR'\n",
        "        x = x[:, ::-1, :, :]\n",
        "    else:\n",
        "        x[:, :, :, 0] -= 103.939\n",
        "        x[:, :, :, 1] -= 116.779\n",
        "        x[:, :, :, 2] -= 123.68\n",
        "        # 'RGB'->'BGR'\n",
        "        x = x[:, :, :, ::-1]\n",
        "    return x\n",
        "\n",
        "\n",
        "def decode_predictions(preds, top=5):\n",
        "    global CLASS_INDEX\n",
        "    if len(preds.shape) != 2 or preds.shape[1] != 1000:\n",
        "        raise ValueError('`decode_predictions` expects '\n",
        "                         'a batch of predictions '\n",
        "                         '(i.e. a 2D array of shape (samples, 1000)). '\n",
        "                         'Found array with shape: ' + str(preds.shape))\n",
        "    if CLASS_INDEX is None:\n",
        "        fpath = get_file('imagenet_class_index.json',\n",
        "                         CLASS_INDEX_PATH,\n",
        "                         cache_subdir='models')\n",
        "        CLASS_INDEX = json.load(open(fpath))\n",
        "    results = []\n",
        "    for pred in preds:\n",
        "        top_indices = pred.argsort()[-top:][::-1]\n",
        "        result = [tuple(CLASS_INDEX[str(i)]) + (pred[i],) for i in top_indices]\n",
        "        results.append(result)\n",
        "    return results\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MC8Yj0Brl_ss"
      },
      "source": [
        "# score\n",
        "\n",
        "import numpy as np\n",
        "from skimage import measure\n",
        "\n",
        "\n",
        "def true_positive(act_blob, pred_blobs, max_dist):\n",
        "    \"\"\"checks whether 1 ground truth nodule was predicted correctly\"\"\"\n",
        "\n",
        "    for pred_blob in pred_blobs:\n",
        "        if np.sqrt(np.abs(np.dot(act_blob - pred_blob, act_blob - pred_blob))) < max_dist:\n",
        "            return 1\n",
        "    return 0\n",
        "\n",
        "\n",
        "def false_positive(act_blobs, pred_blob, max_dist):\n",
        "    \"\"\"checks whether 1 predicted nodule is a false positive\"\"\"\n",
        "\n",
        "    for act_blob in act_blobs:\n",
        "        if np.sqrt(np.abs(np.dot(act_blob - pred_blob, act_blob - pred_blob))) < max_dist:\n",
        "            return 0\n",
        "    return 1\n",
        "\n",
        "\n",
        "def score_slice(act, pred, max_dist):\n",
        "    \"\"\"function that takes ground truth mask and predicted mask for one slice and\n",
        "    outputs the numbers of true positives, false positives, and false negatives.\n",
        "    max_dist is the maximum distance in pixels allowed between the centroid of ground\n",
        "    truth nodule and that of predicted nodule in order to consider the predicted\n",
        "    nodule a true positive.\n",
        "    \"\"\"\n",
        "\n",
        "    act_blobs = map(lambda x: np.array(x.centroid), measure.regionprops(measure.label(act)))\n",
        "    pred_blobs = map(lambda x: np.array(x.centroid), measure.regionprops(measure.label(pred)))\n",
        "    true_positives = 0\n",
        "    false_positives = 0\n",
        "    for act_blob in act_blobs:\n",
        "        true_positives += true_positive(act_blob, pred_blobs, max_dist)\n",
        "    for pred_blob in pred_blobs:\n",
        "        false_positives += false_positive(act_blobs, pred_blob, max_dist)\n",
        "    false_negatives = len(act_blobs) - true_positives\n",
        "\n",
        "    return np.array([true_positives, false_positives, false_negatives])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T1HYshFxlj0k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2dd302d-5970-46a1-dc8b-d494b49f29dc"
      },
      "source": [
        "# detection\n",
        "\n",
        "\"\"\"Script to create training data for U-net using the LUNA dataset.\n",
        "   Saves 3 arrays in the luna directory.\n",
        "   This is a modified version of \n",
        "   https://github.com/booz-allen-hamilton/DSB3Tutorial/blob/master/tutorial_code/LUNA_mask_extraction.py\n",
        "\"\"\"\n",
        "\n",
        "from __future__ import division\n",
        "\n",
        "from glob import glob\n",
        "\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import SimpleITK as sitk\n",
        "from skimage.draw import circle\n",
        "\n",
        "\n",
        "# luna = 'data/luna2016/'  # make sure the paths work!\n",
        "file_list = glob('/content/drive/My Drive/lung/luna_subset/subset1/*.mhd')\n",
        "\n",
        "\n",
        "def get_filename(case):\n",
        "    for f in file_list:\n",
        "        if case in f:\n",
        "            return f\n",
        "\n",
        "\n",
        "def get_nodules(img_file, biggest=False):\n",
        "    \"\"\"Function that returns a list of tuples identifying the nodule locations\n",
        "       in a file, where each tuple is (x-coord, y-coord, z-coord, diameter). If\n",
        "       biggest=True, returns only biggest nodule in file.\n",
        "    \"\"\"\n",
        "     \n",
        "    mini_df = df_node[df_node['file'] == img_file]\n",
        "    if len(mini_df) == 0:\n",
        "        return []\n",
        "\n",
        "    if biggest:\n",
        "        idx = np.argsort(mini_df['diameter_mm'].values)[-1:]\n",
        "    else:\n",
        "        idx = range(len(mini_df))\n",
        "\n",
        "    x = mini_df['coordX'].values[idx]\n",
        "    y = mini_df['coordY'].values[idx]\n",
        "    z = mini_df['coordZ'].values[idx]\n",
        "    diam = mini_df['diameter_mm'].values[idx]\n",
        "    return list(zip(x, y, z, diam))\n",
        "\n",
        "\n",
        "def get_arrays(img_file, biggest=False):\n",
        "    \"\"\"Function that returns 3 lists (masks, large_masks, imgs), where each list is\n",
        "       is a list of numpy arrays. The len of each list is equal to the number of\n",
        "       nodules in img_file (or 1 if biggest=True); i.e., only one slice is added per\n",
        "       nodule. The shape of the arrays is 512x512. Two versions of masks are returned:\n",
        "       masks, which identify nodules by circles of twice the diameter of the ground\n",
        "       truth; and large_masks, with circles of 4x the ground truth diameter.\n",
        "    \"\"\"\n",
        "    \n",
        "    nodules = get_nodules(img_file, biggest)\n",
        "    itk_img = sitk.ReadImage(img_file)\n",
        "    img = sitk.GetArrayFromImage(itk_img)  # zyx\n",
        "    origin = np.array(itk_img.GetOrigin())  # xyz\n",
        "    spacing = np.array(itk_img.GetSpacing())  # xyz\n",
        "    masks = []\n",
        "    large_masks = []\n",
        "    imgs = []\n",
        "    for nodule in nodules:\n",
        "        center = np.array(nodule[:3])  # xyz\n",
        "        v_center = np.rint((center-origin)/spacing).astype(int)  # xyz\n",
        "        v_diam = int(np.round(nodule[3]/spacing[0]))\n",
        "        mask = np.zeros((img.shape[1], img.shape[2]), dtype=np.int8)  # yx\n",
        "        rr, cc = circle(v_center[1], v_center[0], 2*(v_diam/2), shape=mask.shape)\n",
        "        mask[rr, cc] = 1\n",
        "        masks.append(mask)\n",
        "        mask = np.zeros((img.shape[1], img.shape[2]), dtype=np.int8)  # yx\n",
        "        rr, cc = circle(v_center[1], v_center[0], 4*(v_diam/2), shape=mask.shape)\n",
        "        mask[rr, cc] = 1\n",
        "        large_masks.append(mask)\n",
        "        imgs.append(img[v_center[2], :, :])\n",
        "\n",
        "    return masks, large_masks, imgs\n",
        "\n",
        "\n",
        "df_node = pd.read_csv('/content/drive/My Drive/lung/luna2016/annotations.csv')\n",
        "df_node['file'] = df_node['seriesuid'].apply(get_filename)\n",
        "df_node = df_node.dropna()\n",
        "\n",
        "imgs = np.zeros((2000, 512, 512), dtype=np.int16)\n",
        "masks = np.zeros((2000, 512, 512), dtype=np.int8)\n",
        "large_masks = np.zeros((2000, 512, 512), dtype=np.int8)\n",
        "i = 0\n",
        "for img_file in tqdm(file_list):\n",
        "    arrays = get_arrays(img_file)\n",
        "    if len(arrays[0]) == 0:\n",
        "        continue\n",
        "    nb = len(arrays[0])\n",
        "    masks[i:i+nb, :, :] = arrays[0]\n",
        "    large_masks[i:i+nb, :, :] = arrays[1]\n",
        "    imgs[i:i+nb, :, :] = arrays[2]\n",
        "    i += nb\n",
        "\n",
        "imgs = imgs[:i, :, :]\n",
        "masks = masks[:i, :, :]\n",
        "large_masks = large_masks[:i, :, :]\n",
        "\n",
        "# a few masks have nodule locations outside the 512x512 region for some reason.\n",
        "# removing these\n",
        "large_masks_new = np.zeros(large_masks.shape)\n",
        "masks_new = np.zeros(masks.shape)\n",
        "imgs_new = np.zeros(imgs.shape)\n",
        "count = 0\n",
        "for idx, img in enumerate(imgs):\n",
        "    if np.sum(masks[idx]) == 0:\n",
        "        continue\n",
        "    imgs_new[count] = (img - np.mean(img))/np.std(img)\n",
        "    masks_new[count] = masks[idx]\n",
        "    large_masks_new[count] = large_masks[idx]\n",
        "    count += 1\n",
        "\n",
        "imgs = imgs_new[:count]\n",
        "masks = masks_new[:count]\n",
        "large_masks = large_masks_new[:count]\n",
        "\n",
        "# shuffle data\n",
        "np.random.seed(23)\n",
        "idx = np.random.permutation(imgs.shape[0])\n",
        "imgs = imgs[idx, :, :]\n",
        "masks = masks[idx, :, :]\n",
        "large_masks = large_masks[idx, :, :]\n",
        "\n",
        "np.save('imgs.npy', imgs)\n",
        "np.save('masks.npy', masks)\n",
        "np.save('large_masks.npy', large_masks)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 5/5 [00:15<00:00,  3.13s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iMR9aRkzl86f",
        "outputId": "516ac347-40bd-4e86-b4de-d6203a490b24"
      },
      "source": [
        "# unet\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import numpy as np\n",
        "from keras.models import Model, load_model\n",
        "from keras.layers import Input, merge, concatenate, Convolution2D, MaxPooling2D, UpSampling2D,Conv2D\n",
        "from keras.optimizers import Adam\n",
        "from keras import backend as K\n",
        "\n",
        "\n",
        "luna = '/content/sample_data/'\n",
        "\n",
        "\n",
        "def dice_coef(y_true, y_pred):\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    return (2. * intersection + 1) / (K.sum(y_true_f) + K.sum(y_pred_f) + 1)\n",
        "\n",
        "\n",
        "def dice_coef_np(y_true, y_pred):\n",
        "    y_true_f = y_true.flatten()\n",
        "    y_pred_f = y_pred.flatten()\n",
        "    intersection = np.sum(y_true_f * y_pred_f)\n",
        "    return (2. * intersection + 1) / (np.sum(y_true_f) + np.sum(y_pred_f) + 1)\n",
        "\n",
        "\n",
        "def dice_coef_loss(y_true, y_pred):\n",
        "    return -dice_coef(y_true, y_pred)\n",
        "\n",
        "\n",
        "def get_unet():\n",
        "    inputs = Input((512, 512, 1))\n",
        "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n",
        "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv1)\n",
        "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "\n",
        "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(pool1)\n",
        "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv2)\n",
        "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "\n",
        "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool2)\n",
        "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv3)\n",
        "    pool3 = MaxPooling2D((2,2), padding='same')(conv3)\n",
        "\n",
        "    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(pool3)\n",
        "    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv4)\n",
        "    pool4 = MaxPooling2D((2,2), padding='same')(conv4)\n",
        "\n",
        "    conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(pool4)\n",
        "    conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(conv5)\n",
        "\n",
        "    up6 = concatenate([UpSampling2D(size=(2, 2))(conv5), conv4], axis=3)\n",
        "    conv6 = Convolution2D(256, (3, 3), activation='relu', padding='same')(up6)\n",
        "    conv6 = Convolution2D(256, (3, 3), activation='relu', padding='same')(conv6)\n",
        "\n",
        "    up7 = concatenate([UpSampling2D(size=(2, 2))(conv6), conv3], axis=3)\n",
        "    conv7 = Convolution2D(128, (3, 3), activation='relu', padding='same')(up7)\n",
        "    conv7 = Convolution2D(128, (3, 3), activation='relu', padding='same')(conv7)\n",
        "\n",
        "    up8 = concatenate([UpSampling2D(size=(2, 2))(conv7), conv2], axis=3)\n",
        "    conv8 = Convolution2D(64, (3, 3), activation='relu', padding='same')(up8)\n",
        "    conv8 = Convolution2D(64, (3, 3), activation='relu', padding='same')(conv8)\n",
        "\n",
        "    up9 = concatenate([UpSampling2D(size=(2, 2))(conv8), conv1], axis=3)\n",
        "    conv9 = Convolution2D(32, (3, 3), activation='relu', padding='same')(up9)\n",
        "    conv9 = Convolution2D(32, (3, 3), activation='relu', padding='same')(conv9)\n",
        "\n",
        "    conv10 = Convolution2D(1, 1, 1, activation='sigmoid')(conv9)\n",
        "\n",
        "    model = Model(inputs=inputs, outputs=conv10)\n",
        "\n",
        "    model.compile(optimizer=Adam(lr=1.0e-5), loss=dice_coef_loss)\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "K.set_image_data_format('channels_last')\n",
        "\n",
        "imgs = np.load('imgs.npy').astype(np.float32)\n",
        "masks = np.load('masks.npy').astype(np.int)\n",
        "\n",
        "masks_new = np.zeros(masks.shape)\n",
        "imgs_new = np.zeros(imgs.shape)\n",
        "count = 0\n",
        "for idx, img in enumerate(imgs):\n",
        "    if np.sum(masks[idx]) == 0:\n",
        "        continue\n",
        "    imgs_new[count] = (img - np.mean(img))/np.std(img)\n",
        "    masks_new[count] = masks[idx]\n",
        "    count += 1\n",
        "\n",
        "imgs = imgs_new[:count]\n",
        "masks = masks_new[:count]\n",
        "\n",
        "del imgs_new, masks_new\n",
        "\n",
        "spl = int(np.round(imgs.shape[0]*0.7))\n",
        "# tr_imgs = imgs[:spl, np.newaxis, :, :]\n",
        "# tr_masks = masks[:spl, np.newaxis, :, :]\n",
        "# ts_imgs = imgs[spl:, np.newaxis, :, :]\n",
        "# ts_masks = masks[spl:, np.newaxis, :, :]\n",
        "\n",
        "\n",
        "tr_imgs = imgs[:spl, :, :, np.newaxis]\n",
        "tr_masks = masks[:spl, :, :, np.newaxis]\n",
        "ts_imgs = imgs[spl:, :, :, np.newaxis]\n",
        "ts_masks = masks[spl:, :, :, np.newaxis]\n",
        "\n",
        "del imgs, masks\n",
        "\n",
        "unet = get_unet()\n",
        "#unet = load_model(luna + 'unet9.h5', custom_objects={'dice_coef_loss': dice_coef_loss})\n",
        "for i in range(20):\n",
        "    unet.fit(tr_imgs, tr_masks, batch_size=4, epochs=10, verbose=2)\n",
        "    unet.save(lung_folder + 'unet%d.h5' % i)\n",
        "\n",
        "    dc = []\n",
        "    masks_h = unet.predict(tr_imgs, batch_size=4)\n",
        "    for idx in range(masks_h.shape[0]):\n",
        "        dc.append(dice_coef_np(tr_masks[idx, 0, :, :], masks_h[idx, 0, :, :]))\n",
        "    print('train score, epoch:', (i+1)*10, '--', np.mean(dc))\n",
        "\n",
        "    dc = []\n",
        "    masks_h = unet.predict(ts_imgs, batch_size=4)\n",
        "    for idx in range(masks_h.shape[0]):\n",
        "        dc.append(dice_coef_np(ts_masks[idx, 0, :, :], masks_h[idx, 0, :, :]))\n",
        "    print('test score, epoch:', (i+1)*10, '--', np.mean(dc))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1/1 - 18s - loss: -5.7707e-03\n",
            "Epoch 2/10\n",
            "1/1 - 16s - loss: -5.7725e-03\n",
            "Epoch 3/10\n",
            "1/1 - 17s - loss: -5.7745e-03\n",
            "Epoch 4/10\n",
            "1/1 - 16s - loss: -5.7766e-03\n",
            "Epoch 5/10\n",
            "1/1 - 16s - loss: -5.7787e-03\n",
            "Epoch 6/10\n",
            "1/1 - 16s - loss: -5.7808e-03\n",
            "Epoch 7/10\n",
            "1/1 - 16s - loss: -5.7830e-03\n",
            "Epoch 8/10\n",
            "1/1 - 16s - loss: -5.7852e-03\n",
            "Epoch 9/10\n",
            "1/1 - 16s - loss: -5.7874e-03\n",
            "Epoch 10/10\n",
            "1/1 - 16s - loss: -5.7896e-03\n",
            "train score, epoch: 10 -- 0.003910238505105719\n",
            "test score, epoch: 10 -- 0.003928251154406297\n",
            "Epoch 1/10\n",
            "1/1 - 16s - loss: -5.7919e-03\n",
            "Epoch 2/10\n",
            "1/1 - 17s - loss: -5.7941e-03\n",
            "Epoch 3/10\n",
            "1/1 - 16s - loss: -5.7964e-03\n",
            "Epoch 4/10\n",
            "1/1 - 16s - loss: -5.7986e-03\n",
            "Epoch 5/10\n",
            "1/1 - 16s - loss: -5.8009e-03\n",
            "Epoch 6/10\n",
            "1/1 - 16s - loss: -5.8032e-03\n",
            "Epoch 7/10\n",
            "1/1 - 16s - loss: -5.8055e-03\n",
            "Epoch 8/10\n",
            "1/1 - 16s - loss: -5.8079e-03\n",
            "Epoch 9/10\n",
            "1/1 - 16s - loss: -5.8103e-03\n",
            "Epoch 10/10\n",
            "1/1 - 16s - loss: -5.8128e-03\n",
            "train score, epoch: 20 -- 0.003907387419953345\n",
            "test score, epoch: 20 -- 0.003922980617652754\n",
            "Epoch 1/10\n",
            "1/1 - 17s - loss: -5.8154e-03\n",
            "Epoch 2/10\n",
            "1/1 - 16s - loss: -5.8179e-03\n",
            "Epoch 3/10\n",
            "1/1 - 16s - loss: -5.8206e-03\n",
            "Epoch 4/10\n",
            "1/1 - 16s - loss: -5.8232e-03\n",
            "Epoch 5/10\n",
            "1/1 - 16s - loss: -5.8259e-03\n",
            "Epoch 6/10\n",
            "1/1 - 16s - loss: -5.8286e-03\n",
            "Epoch 7/10\n",
            "1/1 - 16s - loss: -5.8314e-03\n",
            "Epoch 8/10\n",
            "1/1 - 16s - loss: -5.8341e-03\n",
            "Epoch 9/10\n",
            "1/1 - 16s - loss: -5.8369e-03\n",
            "Epoch 10/10\n",
            "1/1 - 16s - loss: -5.8396e-03\n",
            "train score, epoch: 30 -- 0.003905403276123022\n",
            "test score, epoch: 30 -- 0.003919156395844843\n",
            "Epoch 1/10\n",
            "1/1 - 16s - loss: -5.8424e-03\n",
            "Epoch 2/10\n",
            "1/1 - 16s - loss: -5.8451e-03\n",
            "Epoch 3/10\n",
            "1/1 - 16s - loss: -5.8478e-03\n",
            "Epoch 4/10\n",
            "1/1 - 16s - loss: -5.8504e-03\n",
            "Epoch 5/10\n",
            "1/1 - 16s - loss: -5.8530e-03\n",
            "Epoch 6/10\n",
            "1/1 - 16s - loss: -5.8556e-03\n",
            "Epoch 7/10\n",
            "1/1 - 16s - loss: -5.8582e-03\n",
            "Epoch 8/10\n",
            "1/1 - 16s - loss: -5.8607e-03\n",
            "Epoch 9/10\n",
            "1/1 - 16s - loss: -5.8633e-03\n",
            "Epoch 10/10\n",
            "1/1 - 16s - loss: -5.8658e-03\n",
            "train score, epoch: 40 -- 0.003905498461101449\n",
            "test score, epoch: 40 -- 0.003918877044634751\n",
            "Epoch 1/10\n",
            "1/1 - 17s - loss: -5.8684e-03\n",
            "Epoch 2/10\n",
            "1/1 - 16s - loss: -5.8710e-03\n",
            "Epoch 3/10\n",
            "1/1 - 16s - loss: -5.8736e-03\n",
            "Epoch 4/10\n",
            "1/1 - 16s - loss: -5.8762e-03\n",
            "Epoch 5/10\n",
            "1/1 - 16s - loss: -5.8788e-03\n",
            "Epoch 6/10\n",
            "1/1 - 16s - loss: -5.8815e-03\n",
            "Epoch 7/10\n",
            "1/1 - 16s - loss: -5.8843e-03\n",
            "Epoch 8/10\n",
            "1/1 - 17s - loss: -5.8871e-03\n",
            "Epoch 9/10\n",
            "1/1 - 16s - loss: -5.8899e-03\n",
            "Epoch 10/10\n",
            "1/1 - 16s - loss: -5.8928e-03\n",
            "train score, epoch: 50 -- 0.003906757547194752\n",
            "test score, epoch: 50 -- 0.003920716995377292\n",
            "Epoch 1/10\n",
            "1/1 - 16s - loss: -5.8958e-03\n",
            "Epoch 2/10\n",
            "1/1 - 16s - loss: -5.8988e-03\n",
            "Epoch 3/10\n",
            "1/1 - 16s - loss: -5.9018e-03\n",
            "Epoch 4/10\n",
            "1/1 - 17s - loss: -5.9049e-03\n",
            "Epoch 5/10\n",
            "1/1 - 16s - loss: -5.9080e-03\n",
            "Epoch 6/10\n",
            "1/1 - 16s - loss: -5.9113e-03\n",
            "Epoch 7/10\n",
            "1/1 - 16s - loss: -5.9146e-03\n",
            "Epoch 8/10\n",
            "1/1 - 16s - loss: -5.9179e-03\n",
            "Epoch 9/10\n",
            "1/1 - 16s - loss: -5.9214e-03\n",
            "Epoch 10/10\n",
            "1/1 - 16s - loss: -5.9249e-03\n",
            "train score, epoch: 60 -- 0.0039088762798990245\n",
            "test score, epoch: 60 -- 0.00392387199756674\n",
            "Epoch 1/10\n",
            "1/1 - 17s - loss: -5.9285e-03\n",
            "Epoch 2/10\n",
            "1/1 - 16s - loss: -5.9322e-03\n",
            "Epoch 3/10\n",
            "1/1 - 16s - loss: -5.9360e-03\n",
            "Epoch 4/10\n",
            "1/1 - 16s - loss: -5.9399e-03\n",
            "Epoch 5/10\n",
            "1/1 - 16s - loss: -5.9439e-03\n",
            "Epoch 6/10\n",
            "1/1 - 16s - loss: -5.9481e-03\n",
            "Epoch 7/10\n",
            "1/1 - 16s - loss: -5.9523e-03\n",
            "Epoch 8/10\n",
            "1/1 - 16s - loss: -5.9567e-03\n",
            "Epoch 9/10\n",
            "1/1 - 16s - loss: -5.9612e-03\n",
            "Epoch 10/10\n",
            "1/1 - 16s - loss: -5.9658e-03\n",
            "train score, epoch: 70 -- 0.003911389232036287\n",
            "test score, epoch: 70 -- 0.0039275336010699555\n",
            "Epoch 1/10\n",
            "1/1 - 17s - loss: -5.9706e-03\n",
            "Epoch 2/10\n",
            "1/1 - 16s - loss: -5.9755e-03\n",
            "Epoch 3/10\n",
            "1/1 - 16s - loss: -5.9806e-03\n",
            "Epoch 4/10\n",
            "1/1 - 16s - loss: -5.9859e-03\n",
            "Epoch 5/10\n",
            "1/1 - 16s - loss: -5.9914e-03\n",
            "Epoch 6/10\n",
            "1/1 - 16s - loss: -5.9970e-03\n",
            "Epoch 7/10\n",
            "1/1 - 16s - loss: -6.0029e-03\n",
            "Epoch 8/10\n",
            "1/1 - 16s - loss: -6.0090e-03\n",
            "Epoch 9/10\n",
            "1/1 - 16s - loss: -6.0154e-03\n",
            "Epoch 10/10\n",
            "1/1 - 16s - loss: -6.0221e-03\n",
            "train score, epoch: 80 -- 0.003914480541828549\n",
            "test score, epoch: 80 -- 0.003932245329723655\n",
            "Epoch 1/10\n",
            "1/1 - 16s - loss: -6.0291e-03\n",
            "Epoch 2/10\n",
            "1/1 - 16s - loss: -6.0364e-03\n",
            "Epoch 3/10\n",
            "1/1 - 16s - loss: -6.0442e-03\n",
            "Epoch 4/10\n",
            "1/1 - 16s - loss: -6.0524e-03\n",
            "Epoch 5/10\n",
            "1/1 - 16s - loss: -6.0610e-03\n",
            "Epoch 6/10\n",
            "1/1 - 16s - loss: -6.0700e-03\n",
            "Epoch 7/10\n",
            "1/1 - 16s - loss: -6.0795e-03\n",
            "Epoch 8/10\n",
            "1/1 - 16s - loss: -6.0898e-03\n",
            "Epoch 9/10\n",
            "1/1 - 16s - loss: -6.1006e-03\n",
            "Epoch 10/10\n",
            "1/1 - 16s - loss: -6.1122e-03\n",
            "train score, epoch: 90 -- 0.003918150332713576\n",
            "test score, epoch: 90 -- 0.003937092310504754\n",
            "Epoch 1/10\n",
            "1/1 - 17s - loss: -6.1245e-03\n",
            "Epoch 2/10\n",
            "1/1 - 16s - loss: -6.1377e-03\n",
            "Epoch 3/10\n",
            "1/1 - 16s - loss: -6.1519e-03\n",
            "Epoch 4/10\n",
            "1/1 - 16s - loss: -6.1670e-03\n",
            "Epoch 5/10\n",
            "1/1 - 16s - loss: -6.1832e-03\n",
            "Epoch 6/10\n",
            "1/1 - 16s - loss: -6.2006e-03\n",
            "Epoch 7/10\n",
            "1/1 - 16s - loss: -6.2194e-03\n",
            "Epoch 8/10\n",
            "1/1 - 16s - loss: -6.2396e-03\n",
            "Epoch 9/10\n",
            "1/1 - 16s - loss: -6.2616e-03\n",
            "Epoch 10/10\n",
            "1/1 - 16s - loss: -6.2856e-03\n",
            "train score, epoch: 100 -- 0.003920885178930503\n",
            "test score, epoch: 100 -- 0.003941282492457041\n",
            "Epoch 1/10\n",
            "1/1 - 17s - loss: -6.3117e-03\n",
            "Epoch 2/10\n",
            "1/1 - 16s - loss: -6.3401e-03\n",
            "Epoch 3/10\n",
            "1/1 - 16s - loss: -6.3712e-03\n",
            "Epoch 4/10\n",
            "1/1 - 16s - loss: -6.4051e-03\n",
            "Epoch 5/10\n",
            "1/1 - 16s - loss: -6.4422e-03\n",
            "Epoch 6/10\n",
            "1/1 - 16s - loss: -6.4829e-03\n",
            "Epoch 7/10\n",
            "1/1 - 16s - loss: -6.5278e-03\n",
            "Epoch 8/10\n",
            "1/1 - 16s - loss: -6.5776e-03\n",
            "Epoch 9/10\n",
            "1/1 - 16s - loss: -6.6334e-03\n",
            "Epoch 10/10\n",
            "1/1 - 16s - loss: -6.6961e-03\n",
            "train score, epoch: 110 -- 0.003923668012018557\n",
            "test score, epoch: 110 -- 0.003944809979955121\n",
            "Epoch 1/10\n",
            "1/1 - 16s - loss: -6.7670e-03\n",
            "Epoch 2/10\n",
            "1/1 - 16s - loss: -6.8466e-03\n",
            "Epoch 3/10\n",
            "1/1 - 16s - loss: -6.9368e-03\n",
            "Epoch 4/10\n",
            "1/1 - 16s - loss: -7.0390e-03\n",
            "Epoch 5/10\n",
            "1/1 - 16s - loss: -7.1555e-03\n",
            "Epoch 6/10\n",
            "1/1 - 16s - loss: -7.2882e-03\n",
            "Epoch 7/10\n",
            "1/1 - 16s - loss: -7.4397e-03\n",
            "Epoch 8/10\n",
            "1/1 - 16s - loss: -7.6132e-03\n",
            "Epoch 9/10\n",
            "1/1 - 16s - loss: -7.8115e-03\n",
            "Epoch 10/10\n",
            "1/1 - 16s - loss: -8.0364e-03\n",
            "train score, epoch: 120 -- 0.003930977072174311\n",
            "test score, epoch: 120 -- 0.003952592055058372\n",
            "Epoch 1/10\n",
            "1/1 - 17s - loss: -8.2895e-03\n",
            "Epoch 2/10\n",
            "1/1 - 16s - loss: -8.5730e-03\n",
            "Epoch 3/10\n",
            "1/1 - 16s - loss: -8.8905e-03\n",
            "Epoch 4/10\n",
            "1/1 - 16s - loss: -9.2468e-03\n",
            "Epoch 5/10\n",
            "1/1 - 16s - loss: -9.6475e-03\n",
            "Epoch 6/10\n",
            "1/1 - 16s - loss: -1.0100e-02\n",
            "Epoch 7/10\n",
            "1/1 - 16s - loss: -1.0608e-02\n",
            "Epoch 8/10\n",
            "1/1 - 16s - loss: -1.1178e-02\n",
            "Epoch 9/10\n",
            "1/1 - 16s - loss: -1.1818e-02\n",
            "Epoch 10/10\n",
            "1/1 - 16s - loss: -1.2550e-02\n",
            "train score, epoch: 130 -- 0.00395943988699168\n",
            "test score, epoch: 130 -- 0.003977238176582918\n",
            "Epoch 1/10\n",
            "1/1 - 16s - loss: -1.3400e-02\n",
            "Epoch 2/10\n",
            "1/1 - 16s - loss: -1.4410e-02\n",
            "Epoch 3/10\n",
            "1/1 - 16s - loss: -1.5650e-02\n",
            "Epoch 4/10\n",
            "1/1 - 16s - loss: -1.7198e-02\n",
            "Epoch 5/10\n",
            "1/1 - 16s - loss: -1.9147e-02\n",
            "Epoch 6/10\n",
            "1/1 - 16s - loss: -2.1603e-02\n",
            "Epoch 7/10\n",
            "1/1 - 16s - loss: -2.4682e-02\n",
            "Epoch 8/10\n",
            "1/1 - 16s - loss: -2.8529e-02\n",
            "Epoch 9/10\n",
            "1/1 - 16s - loss: -3.3341e-02\n",
            "Epoch 10/10\n",
            "1/1 - 16s - loss: -3.9392e-02\n",
            "train score, epoch: 140 -- 0.004258834992828439\n",
            "test score, epoch: 140 -- 0.004394011469780611\n",
            "Epoch 1/10\n",
            "1/1 - 17s - loss: -4.7117e-02\n",
            "Epoch 2/10\n",
            "1/1 - 16s - loss: -5.7178e-02\n",
            "Epoch 3/10\n",
            "1/1 - 16s - loss: -7.0451e-02\n",
            "Epoch 4/10\n",
            "1/1 - 16s - loss: -8.8011e-02\n",
            "Epoch 5/10\n",
            "1/1 - 16s - loss: -1.1076e-01\n",
            "Epoch 6/10\n",
            "1/1 - 16s - loss: -1.3802e-01\n",
            "Epoch 7/10\n",
            "1/1 - 16s - loss: -1.5016e-01\n",
            "Epoch 8/10\n",
            "1/1 - 16s - loss: -1.7258e-01\n",
            "Epoch 9/10\n",
            "1/1 - 16s - loss: -2.0900e-01\n",
            "Epoch 10/10\n",
            "1/1 - 16s - loss: -2.3168e-01\n",
            "train score, epoch: 150 -- 0.005949923510113428\n",
            "test score, epoch: 150 -- 0.007069542263966542\n",
            "Epoch 1/10\n",
            "1/1 - 16s - loss: -2.4822e-01\n",
            "Epoch 2/10\n",
            "1/1 - 16s - loss: -2.8842e-01\n",
            "Epoch 3/10\n",
            "1/1 - 16s - loss: -3.1678e-01\n",
            "Epoch 4/10\n",
            "1/1 - 16s - loss: -3.2686e-01\n",
            "Epoch 5/10\n",
            "1/1 - 16s - loss: -3.6237e-01\n",
            "Epoch 6/10\n",
            "1/1 - 16s - loss: -4.0717e-01\n",
            "Epoch 7/10\n",
            "1/1 - 16s - loss: -3.9761e-01\n",
            "Epoch 8/10\n",
            "1/1 - 16s - loss: -4.3193e-01\n",
            "Epoch 9/10\n",
            "1/1 - 16s - loss: -4.8657e-01\n",
            "Epoch 10/10\n",
            "1/1 - 16s - loss: -4.5570e-01\n",
            "train score, epoch: 160 -- 0.013176302205860396\n",
            "test score, epoch: 160 -- 0.016005409054561468\n",
            "Epoch 1/10\n",
            "1/1 - 16s - loss: -5.2984e-01\n",
            "Epoch 2/10\n",
            "1/1 - 16s - loss: -5.3791e-01\n",
            "Epoch 3/10\n",
            "1/1 - 16s - loss: -5.5776e-01\n",
            "Epoch 4/10\n",
            "1/1 - 16s - loss: -6.0945e-01\n",
            "Epoch 5/10\n",
            "1/1 - 16s - loss: -6.0548e-01\n",
            "Epoch 6/10\n",
            "1/1 - 16s - loss: -6.5082e-01\n",
            "Epoch 7/10\n",
            "1/1 - 16s - loss: -6.5462e-01\n",
            "Epoch 8/10\n",
            "1/1 - 16s - loss: -6.5927e-01\n",
            "Epoch 9/10\n",
            "1/1 - 16s - loss: -7.0911e-01\n",
            "Epoch 10/10\n",
            "1/1 - 16s - loss: -6.8290e-01\n",
            "train score, epoch: 170 -- 0.05045814729609558\n",
            "test score, epoch: 170 -- 0.03366401402119334\n",
            "Epoch 1/10\n",
            "1/1 - 16s - loss: -7.1293e-01\n",
            "Epoch 2/10\n",
            "1/1 - 16s - loss: -7.4973e-01\n",
            "Epoch 3/10\n",
            "1/1 - 16s - loss: -7.1560e-01\n",
            "Epoch 4/10\n",
            "1/1 - 16s - loss: -7.7278e-01\n",
            "Epoch 5/10\n",
            "1/1 - 16s - loss: -7.7634e-01\n",
            "Epoch 6/10\n",
            "1/1 - 16s - loss: -7.6895e-01\n",
            "Epoch 7/10\n",
            "1/1 - 16s - loss: -8.1558e-01\n",
            "Epoch 8/10\n",
            "1/1 - 16s - loss: -7.9594e-01\n",
            "Epoch 9/10\n",
            "1/1 - 16s - loss: -8.1460e-01\n",
            "Epoch 10/10\n",
            "1/1 - 16s - loss: -8.4149e-01\n",
            "train score, epoch: 180 -- 0.1627848852569303\n",
            "test score, epoch: 180 -- 0.06067922356824338\n",
            "Epoch 1/10\n",
            "1/1 - 16s - loss: -8.2413e-01\n",
            "Epoch 2/10\n",
            "1/1 - 16s - loss: -8.4895e-01\n",
            "Epoch 3/10\n",
            "1/1 - 16s - loss: -8.6374e-01\n",
            "Epoch 4/10\n",
            "1/1 - 16s - loss: -8.5393e-01\n",
            "Epoch 5/10\n",
            "1/1 - 16s - loss: -8.6890e-01\n",
            "Epoch 6/10\n",
            "1/1 - 16s - loss: -8.8443e-01\n",
            "Epoch 7/10\n",
            "1/1 - 16s - loss: -8.7738e-01\n",
            "Epoch 8/10\n",
            "1/1 - 16s - loss: -8.7549e-01\n",
            "Epoch 9/10\n",
            "1/1 - 16s - loss: -8.9351e-01\n",
            "Epoch 10/10\n",
            "1/1 - 16s - loss: -9.0458e-01\n",
            "train score, epoch: 190 -- 0.2892350180239226\n",
            "test score, epoch: 190 -- 0.096226426348988\n",
            "Epoch 1/10\n",
            "1/1 - 16s - loss: -9.0345e-01\n",
            "Epoch 2/10\n",
            "1/1 - 17s - loss: -9.0105e-01\n",
            "Epoch 3/10\n",
            "1/1 - 16s - loss: -8.9159e-01\n",
            "Epoch 4/10\n",
            "1/1 - 16s - loss: -8.9000e-01\n",
            "Epoch 5/10\n",
            "1/1 - 16s - loss: -9.0154e-01\n",
            "Epoch 6/10\n",
            "1/1 - 16s - loss: -9.1762e-01\n",
            "Epoch 7/10\n",
            "1/1 - 16s - loss: -9.2625e-01\n",
            "Epoch 8/10\n",
            "1/1 - 16s - loss: -9.2825e-01\n",
            "Epoch 9/10\n",
            "1/1 - 16s - loss: -9.2532e-01\n",
            "Epoch 10/10\n",
            "1/1 - 16s - loss: -9.1131e-01\n",
            "train score, epoch: 200 -- 0.36085659739236625\n",
            "test score, epoch: 200 -- 0.12315851866015827\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PhRfcLx4l4rq"
      },
      "source": [
        "# segmentation\n",
        "\n",
        "from __future__ import division\n",
        "\n",
        "import numpy as np\n",
        "from skimage import measure\n",
        "from sklearn.cluster import KMeans\n",
        "from skimage.transform import resize\n",
        "from skimage import morphology\n",
        "\n",
        "\n",
        "def segment_lungs(img, nodule_mask=None):\n",
        "    mean = np.mean(img)\n",
        "    std = np.std(img)\n",
        "    img = (img - mean) / std\n",
        "    img = img.astype(np.float64)\n",
        "    middle = img[100:400, 100:400]\n",
        "    mean = np.mean(middle)\n",
        "    img_max = np.max(img)\n",
        "    img_min = np.min(img)\n",
        "\n",
        "    img[img == img_max] = mean\n",
        "    img[img == img_min] = mean\n",
        "\n",
        "    kmeans = KMeans(n_clusters=2).fit(np.reshape(middle, [np.prod(middle.shape), 1]))\n",
        "    centers = sorted(kmeans.cluster_centers_.flatten())\n",
        "    threshold = np.mean(centers)\n",
        "    thresh_img = np.where(img < threshold, 1.0, 0.0)\n",
        "\n",
        "    eroded = morphology.erosion(thresh_img, np.ones([4, 4]))\n",
        "    dilation = morphology.dilation(eroded, np.ones([10, 10]))\n",
        "\n",
        "    labels = measure.label(dilation)\n",
        "    regions = measure.regionprops(labels)\n",
        "    good_labels = []\n",
        "    for prop in regions:\n",
        "        B = prop.bbox\n",
        "        if B[2] - B[0] < 475 and B[3] - B[1] < 475 and B[0] > 40 and B[2] < 472:\n",
        "            good_labels.append(prop.label)\n",
        "    mask = np.ndarray([512, 512], dtype=np.int8)\n",
        "    mask[:] = 0\n",
        "\n",
        "    for N in good_labels:\n",
        "        mask += np.where(labels == N, 1, 0)\n",
        "\n",
        "    mask = morphology.dilation(mask, np.ones([10, 10]))\n",
        "\n",
        "    img = mask * img\n",
        "\n",
        "    new_mean = np.mean(img[mask > 0])\n",
        "    new_std = np.std(img[mask > 0])\n",
        "\n",
        "    old_min = np.min(img)\n",
        "    img[img == old_min] = new_mean - 1.2 * new_std\n",
        "    img = (img - new_mean) / new_std\n",
        "\n",
        "    labels = measure.label(mask)\n",
        "    regions = measure.regionprops(labels)\n",
        "\n",
        "    min_row = 512\n",
        "    max_row = 0\n",
        "    min_col = 512\n",
        "    max_col = 0\n",
        "    for prop in regions:\n",
        "        B = prop.bbox\n",
        "        if min_row > B[0]:\n",
        "            min_row = B[0]\n",
        "        if min_col > B[1]:\n",
        "            min_col = B[1]\n",
        "        if max_row < B[2]:\n",
        "            max_row = B[2]\n",
        "        if max_col < B[3]:\n",
        "            max_col = B[3]\n",
        "    width = max_col - min_col\n",
        "    height = max_row - min_row\n",
        "    if width > height:\n",
        "        max_row = min_row + width\n",
        "    else:\n",
        "        max_col = min_col + height\n",
        "\n",
        "    img = img[min_row:max_row, min_col:max_col]\n",
        "    if max_row - min_row < 5 or max_col - min_col < 5:\n",
        "        return ()\n",
        "    else:\n",
        "        mean = np.mean(img)\n",
        "        img -= mean\n",
        "        img_min = np.min(img)\n",
        "        img_max = np.max(img)\n",
        "        img /= (img_max - img_min)\n",
        "        new_img = resize(img, [512, 512])\n",
        "        if isinstance(nodule_mask, np.ndarray):\n",
        "            nodule_mask = nodule_mask.astype(np.float64)\n",
        "            new_nodule_mask = resize(nodule_mask[min_row:max_row, min_col:max_col], [512, 512])\n",
        "        else:\n",
        "            new_nodule_mask = 0\n",
        "\n",
        "        return new_img, new_nodule_mask\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rcUVF8bLlc0a",
        "outputId": "dc84edcf-122c-477f-8dcd-8c44eb65918b"
      },
      "source": [
        "# cropping\n",
        "\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "import pickle\n",
        "from glob import glob\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pydicom as dicom\n",
        "from keras import backend as K\n",
        "from skimage.feature import hog\n",
        "from skimage.feature import local_binary_pattern\n",
        "# from segmentation import segment_lungs\n",
        "from skimage import measure\n",
        "# from score import false_positive\n",
        "from sklearn.cluster import k_means\n",
        "from sklearn.svm import SVC\n",
        "from keras.models import load_model\n",
        "from scipy.ndimage.measurements import label\n",
        "import cv2\n",
        "import io\n",
        "\n",
        "import time\n",
        "\n",
        "# databowl = '/media/data/kaggle/'\n",
        "# kaggle_datafolder = '/media/data/kaggle/'\n",
        "# kaggle_metadata = './data/kaggle/'\n",
        "K.set_image_data_format('channels_last')\n",
        "\n",
        "\n",
        "def get_patch_coord(centroid, patch_size):\n",
        "    if centroid[0] < patch_size / 2:\n",
        "        r_min = 0\n",
        "        r_max = patch_size\n",
        "    elif centroid[0] > 512 - patch_size / 2:\n",
        "        r_min = 512 - patch_size\n",
        "        r_max = 512\n",
        "    else:\n",
        "        r_min = centroid[0] - patch_size / 2\n",
        "        r_max = centroid[0] + patch_size / 2\n",
        "\n",
        "    if centroid[1] < patch_size / 2:\n",
        "        c_min = 0\n",
        "        c_max = patch_size\n",
        "    elif centroid[1] > 512 - patch_size / 2:\n",
        "        c_min = 512 - patch_size\n",
        "        c_max = 512\n",
        "    else:\n",
        "        c_min = centroid[1] - patch_size / 2\n",
        "        c_max = centroid[1] + patch_size / 2\n",
        "\n",
        "    return int(r_min), int(r_max), int(c_min), int(c_max)\n",
        "\n",
        "\n",
        "def read_imgs(patient):\n",
        "    img_files = glob(lung_folder + 'lung_subset_test/' + patient + '/*')\n",
        "    slices = [dicom.read_file(img_file) for img_file in img_files]\n",
        "    slices.sort(key=lambda x: float(x.ImagePositionPatient[2]))\n",
        "    imgs = np.stack([s.pixel_array for s in slices]).astype(np.float64)\n",
        "    new_imgs = np.zeros(imgs.shape, dtype=np.float32)\n",
        "    count = 0\n",
        "    for img in imgs[int(0.12*imgs.shape[0]):int(0.97*imgs.shape[0])]:\n",
        "        segmented = segment_lungs(img)\n",
        "        if len(segmented) == 0:\n",
        "            continue\n",
        "        new_imgs[count] = (segmented[0] - np.mean(segmented[0])) / np.std(segmented[0])\n",
        "        count += 1\n",
        "\n",
        "    return new_imgs[:count]\n",
        "\n",
        "\n",
        "def get_filtered_nodules(imgs, unet):\n",
        "    nodules = []\n",
        "    masks = unet.predict(imgs[:, np.newaxis, :, :], batch_size=4).astype(int)\n",
        "    for i in range(masks.shape[0] - 1):\n",
        "        mask = masks[i, 0]\n",
        "        next_mask = masks[i + 1, 0]\n",
        "        blobs = map(lambda x: np.array(x.centroid), measure.regionprops(measure.label(mask)))\n",
        "        next_blobs = map(lambda x: np.array(x.centroid), measure.regionprops(measure.label(next_mask)))\n",
        "        for blob in blobs:\n",
        "            if not false_positive(next_blobs, blob, 15):\n",
        "                r_min, r_max, c_min, c_max = get_patch_coord(blob, 50)\n",
        "                nodules.append(imgs[i, r_min:r_max, c_min:c_max])\n",
        "\n",
        "    return np.array(nodules, dtype=np.float32)\n",
        "\n",
        "\n",
        "def get_masks(imgs, unet):\n",
        "    masks = unet.predict(imgs[:, :, :, np.newaxis], batch_size=4).astype(int)\n",
        "    return masks\n",
        "\n",
        "\n",
        "def get_all_nodules(imgs, unet):\n",
        "    nodules = []\n",
        "    masks = unet.predict(imgs[:, np.newaxis, :, :], batch_size=4).astype(int)\n",
        "    for idx, mask in enumerate(masks):\n",
        "        blobs = map(lambda x: np.array(x.centroid), measure.regionprops(measure.label(mask[0])))\n",
        "        for blob in blobs:\n",
        "            r_min, r_max, c_min, c_max = get_patch_coord(blob, 50)\n",
        "            nodules.append(imgs[idx, r_min:r_max, c_min:c_max])\n",
        "\n",
        "    return np.array(nodules, dtype=np.float32)\n",
        "\n",
        "\n",
        "def dice_coef(y_true, y_pred):\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "\n",
        "    return (2. * intersection + 1) / (K.sum(y_true_f) + K.sum(y_pred_f) + 1)\n",
        "\n",
        "\n",
        "def dice_coef_np(y_true, y_pred):\n",
        "    y_true_f = y_true.flatten()\n",
        "    y_pred_f = y_pred.flatten()\n",
        "    intersection = np.sum(y_true_f * y_pred_f)\n",
        "\n",
        "    return (2. * intersection + 1) / (np.sum(y_true_f) + np.sum(y_pred_f) + 1)\n",
        "\n",
        "\n",
        "def dice_coef_loss(y_true, y_pred):\n",
        "\n",
        "    return -1*dice_coef(y_true, y_pred)\n",
        "\n",
        "\n",
        "def crop_nodule(img, bbox):\n",
        "    padding = 5\n",
        "    y_start = np.clip(bbox[0][1] - padding, 0, 512)\n",
        "    y_end = np.clip(bbox[1][1] + padding, 0, 512)\n",
        "    x_start = np.clip(bbox[0][0] - padding, 0, 512)\n",
        "    x_end = np.clip(bbox[1][0] + padding, 0, 512)\n",
        "    cropped = img[y_start:y_end, x_start:x_end]\n",
        "    cropped = cv2.resize(cropped, (50, 50))\n",
        "    return cropped\n",
        "\n",
        "\n",
        "def draw_labeled_bboxes(img, labels):\n",
        "    copied = np.copy(img)\n",
        "    bboxes = []\n",
        "    # Iterate through all detected nodules\n",
        "    for nodule_number in range(1, labels[1]+1):\n",
        "        # Find pixels with each nodule_number label value\n",
        "        nonzero = (labels[0] == nodule_number).nonzero()\n",
        "        # Identify x and y values of those pixels\n",
        "        nonzeroy = np.array(nonzero[0])\n",
        "        nonzerox = np.array(nonzero[1])\n",
        "        # Define a bounding box based on min/max x and y\n",
        "        width = np.max(nonzerox) - np.min(nonzerox)\n",
        "        height = np.max(nonzerox) - np.max(nonzeroy)\n",
        "\n",
        "        if width > 5 and height > 5:\n",
        "            bbox = ((np.min(nonzerox), np.min(nonzeroy)), (np.max(nonzerox), np.max(nonzeroy)))\n",
        "            bboxes.append(bbox)\n",
        "            # Draw the box on the image\n",
        "            #cv2.rectangle(img, bbox[0], bbox[1], (10, 10, 10), 2)\n",
        "            #copied = cv2.addWeighted(copied, 1.0, img, 1.0, 0.)\n",
        "\n",
        "    # Return the image\n",
        "    return copied, bboxes\n",
        "\n",
        "\n",
        "def test_nodules():\n",
        "    unet = load_model(lung_folder + '/unet19.h5', custom_objects={'dice_coef_loss': dice_coef_loss})\n",
        "\n",
        "    df = pd.read_csv(lung_folder + 'kaggle/stage1_labels_subset.csv')\n",
        "    test_df = pd.read_csv(lung_folder + 'kaggle/stage1_sample_submission_subset.csv')\n",
        "    test_df = test_df[:2]\n",
        "\n",
        "    tr_nodules = []\n",
        "\n",
        "    for idx, patient in enumerate(test_df['id']):\n",
        "        print(idx, patient)\n",
        "        imgs = read_imgs(lung_folder + 'lung_subset_test/' + patient)\n",
        "        tr_nodules.append((get_filtered_nodules(imgs, unet)), patient)\n",
        "\n",
        "    np.save(lung_folder + 'test_nodules.npy', np.array(tr_nodules))\n",
        "\n",
        "\n",
        "def train_masks():\n",
        "    unet = load_model(lung_folder + '/unet19.h5', custom_objects={'dice_coef_loss': dice_coef_loss})\n",
        "    train_df = pd.read_csv(lung_folder + 'kaggle/stage1_labels_subset.csv')\n",
        "    num_samples = len(train_df)\n",
        "    batch_size = 50\n",
        "    batch = []\n",
        "    print(\"Number of training samples:\", num_samples)\n",
        "    train_df.head()\n",
        "    for i in range(28):\n",
        "        nodules = []\n",
        "        batch_start = i * batch_size\n",
        "        batch_end = batch_start + batch_size\n",
        "        ts = time.time()\n",
        "        for idx, patient in train_df[batch_start:batch_end].iterrows():\n",
        "            if idx % 5 == 0:\n",
        "                print(i, idx, patient)\n",
        "            slices = read_imgs(lung_folder + 'lung_subset/' + patient['id'])\n",
        "            masks = get_masks(slices, unet)\n",
        "            nodules.append((masks, patient['id'], patient['cancer']))\n",
        "            del masks\n",
        "            del slices\n",
        "        np.save(lung_folder + 'train_masks%d.npy' % i, np.array(nodules))\n",
        "        te = time.time()\n",
        "        print(\"Batch runtime:\", te - ts)\n",
        "\n",
        "\n",
        "def crop_nodules_heatmap():\n",
        "    unet = load_model(lung_folder + '/unet19.h5', custom_objects={'dice_coef_loss': dice_coef_loss})\n",
        "    train_df = pd.read_csv(lung_folder + 'kaggle/stage1_labels.csv')\n",
        "    num_samples = len(train_df)\n",
        "    batch_size = 200\n",
        "    batch = []\n",
        "    print(\"Number of training samples:\", num_samples)\n",
        "    for i in range(7):\n",
        "        nodules = []\n",
        "        batch_start = i * batch_size\n",
        "        batch_end = batch_start + batch_size\n",
        "        ts = time.time()\n",
        "        for idx, patient in train_df[batch_start:batch_end].iterrows():\n",
        "            if idx % 50 == 0:\n",
        "                print(i, idx, patient)\n",
        "            patient_nodules = []\n",
        "            # Get all slice masks from patient\n",
        "            slices = read_imgs(lung_folder + 'lung_subset/' + patient['id'])\n",
        "\n",
        "            # get predicted masks\n",
        "            predicted = get_masks(slices, unet)\n",
        "\n",
        "            # Create heatmap from all slices\n",
        "            threshold = 2.0\n",
        "            heatmap = np.sum(predicted, axis=0)[0]\n",
        "\n",
        "            # threshold to keep hottest regions\n",
        "            thresh_heatmap = np.copy(heatmap)\n",
        "            thresh_heatmap[thresh_heatmap < threshold] = 0\n",
        "            xy = thresh_heatmap.nonzero()\n",
        "            thresh_heatmap[xy[0], xy[1]] = 1.\n",
        "\n",
        "            # get bounding boxes on hottest nodule regions\n",
        "            labels = label(thresh_heatmap)\n",
        "            img_bbox, bboxes = draw_labeled_bboxes(np.copy(thresh_heatmap), labels)\n",
        "\n",
        "            padding = 5\n",
        "            # for each slice, keep only if dice coefficient > threshold\n",
        "            for idx, predicted_slice in enumerate(predicted):\n",
        "                for bbox in bboxes:\n",
        "                    # isolate nodules\n",
        "                    tmp = np.zeros((512, 512))\n",
        "                    y_start = np.clip(bbox[0][1] - padding, 0, 512)\n",
        "                    y_end = np.clip(bbox[1][1] + padding, 0, 512)\n",
        "                    x_start = np.clip(bbox[0][0] - padding, 0, 512)\n",
        "                    x_end = np.clip(bbox[1][0] + padding, 0, 512)\n",
        "                    tmp[y_start:y_end, x_start:x_end] = 1\n",
        "\n",
        "                    single_nodule_mask = np.logical_and(thresh_heatmap, tmp)\n",
        "\n",
        "                    # Check if nodule covers area\n",
        "                    dice_coefficient = dice_coef_np(single_nodule_mask, predicted_slice[0])\n",
        "                    if dice_coefficient >= 0.40:\n",
        "                        cropped_nodule = crop_nodule(slices[idx], bbox)\n",
        "                        patient_nodules.append(cropped_nodule)\n",
        "\n",
        "            nodules.append((np.array(patient_nodules), patient['id'], patient['cancer']))\n",
        "            #print(\"Number of nodules detected for this patient\",len(patient_nodules))\n",
        "\n",
        "        np.save(lung_folder + 'cropped_heatmap_nodules_heat2_dice40%d.npy' % i, np.array(nodules))\n",
        "        te = time.time()\n",
        "        print(\"Batch runtime:\", te - ts)\n",
        "\n",
        "\n",
        "def crop_test_nodules():\n",
        "    unet = load_model(lung_folder + '/unet19.h5', custom_objects={'dice_coef_loss': dice_coef_loss})\n",
        "    test_df = pd.read_csv(lung_folder + 'kaggle/stage1_sample_submission_subset.csv')\n",
        "    test_df = test_df[:2]\n",
        "    num_samples = len(test_df)\n",
        "    print(\"Number of testing samples:\", num_samples)\n",
        "    ts = time.time()\n",
        "    nodules = []\n",
        "    for idx, patient in test_df.iterrows():\n",
        "        if idx % 25 == 0:\n",
        "            print(idx, patient, len(nodules))\n",
        "        patient_nodules = []\n",
        "        # Get all slice masks from patient\n",
        "        slices = read_imgs(patient['id'])\n",
        "\n",
        "        # get predicted masks\n",
        "        predicted = get_masks(slices, unet)\n",
        "\n",
        "        # Create heatmap from all slices\n",
        "        threshold = 2.0\n",
        "        heatmap = np.sum(predicted, axis=0)[0]\n",
        "\n",
        "        # threshold to keep hottest regions\n",
        "        thresh_heatmap = np.copy(heatmap)\n",
        "        thresh_heatmap[thresh_heatmap < threshold] = 0\n",
        "        xy = thresh_heatmap.nonzero()\n",
        "        thresh_heatmap[xy[0], xy[1]] = 1.\n",
        "\n",
        "        # get bounding boxes on hottest nodule regions\n",
        "        labels = label(thresh_heatmap)\n",
        "        img_bbox, bboxes = draw_labeled_bboxes(np.copy(thresh_heatmap), labels)\n",
        "\n",
        "        padding = 5\n",
        "        # for each slice, keep only if dice coefficient > threshold\n",
        "        for idx, predicted_slice in enumerate(predicted):\n",
        "            for bbox in bboxes:\n",
        "                # isolate nodules\n",
        "                tmp = np.zeros((512, 512))\n",
        "                y_start = np.clip(bbox[0][1] - padding, 0, 512)\n",
        "                y_end = np.clip(bbox[1][1] + padding, 0, 512)\n",
        "                x_start = np.clip(bbox[0][0] - padding, 0, 512)\n",
        "                x_end = np.clip(bbox[1][0] + padding, 0, 512)\n",
        "                tmp[y_start:y_end, x_start:x_end] = 1\n",
        "\n",
        "                single_nodule_mask = np.logical_and(thresh_heatmap, tmp)\n",
        "\n",
        "                # Check if nodule covers area\n",
        "                dice_coefficient = dice_coef_np(single_nodule_mask, predicted_slice[0])\n",
        "                if dice_coefficient >= 0.40:\n",
        "                    cropped_nodule = crop_nodule(slices[idx], bbox)\n",
        "                    patient_nodules.append(cropped_nodule)\n",
        "\n",
        "        nodules.append((np.array(patient_nodules), patient['id']))\n",
        "        #print(\"Number of nodules detected for this patient\",len(patient_nodules))\n",
        "\n",
        "    np.save(lung_folder + 'test_cropped_heatmap_nodules_heat2_dice40.npy', np.array(nodules))\n",
        "    te = time.time()\n",
        "    print(\"Batch runtime:\", te - ts)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    crop_test_nodules()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of testing samples: 2\n",
            "0 id        026470d51482c93efc18b9803159c960\n",
            "cancer                                 0.5\n",
            "Name: 0, dtype: object 0\n",
            "Batch runtime: 675.7902569770813\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:324: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fvZlPazkvKcB",
        "outputId": "d112828f-b7e4-4343-9ab9-e42a0442018c"
      },
      "source": [
        "nodule_files = glob.glob(lung_folder + '*cropped_heatmap_nodules*')\n",
        "nodule_files\n",
        "# nodule_files.sort()\n",
        "data = np.load(nodule_files[0], allow_pickle=True)\n",
        "data\n",
        "# for nodule_file in nodule_files[0:]:\n",
        "#     tmp = np.load(nodule_file, allow_pickle=True)\n",
        "#     print(tmp)\n",
        "#     data = np.vstack((data, tmp))\n",
        "#     print(data)\n",
        "  \n",
        "# print(\"Number of patients:\", data.shape)\n",
        "# print(\"Patient shape:\", data[0][0].shape)\n",
        "# return data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[array([], dtype=float64), '026470d51482c93efc18b9803159c960'],\n",
              "       [array([], dtype=float64), '031b7ec4fe96a3b035a8196264a8c8c3']],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FPj5IMWjlhUp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        },
        "outputId": "81457648-352f-4dce-a701-7db9ef45be7e"
      },
      "source": [
        "# classify nodules\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os.path as path\n",
        "import glob\n",
        "import pickle\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Activation\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.utils import np_utils\n",
        "from keras import backend as K\n",
        "\n",
        "\n",
        "# kaggle_datafolder = '/media/data/kaggle/'\n",
        "# kaggle_metadata = './data/kaggle/'\n",
        "K.set_image_data_format('channels_last')\n",
        "\n",
        "\n",
        "# def load_pickles():\n",
        "#     nodule_files = glob.glob(kaggle_datafolder + '*.pickle')\n",
        "#     with open(nodule_files[0], \"rb\") as f:\n",
        "#         data = pickle.load(f, encoding='latin1')\n",
        "\n",
        "#     for nodule_file in nodule_files[1:]:\n",
        "#         with open(nodule_file, \"rb\") as f:\n",
        "#             tmp = pickle.load(f, encoding='latin1')\n",
        "#             data = np.hstack((data, tmp))\n",
        "            \n",
        "#     data = np.swapaxes(data, 0, 1)    \n",
        "#     print(\"Number of patients:\", data.shape)\n",
        "#     print(\"Patient shape:\", data[0][0].shape)\n",
        "#     return data\n",
        "\n",
        "\n",
        "def load_cropped_nodules():\n",
        "    nodule_files = glob.glob(lung_folder + '*cropped_heatmap_nodules*')\n",
        "    nodule_files.sort()\n",
        "    data = np.load(nodule_files[0])\n",
        "    for nodule_file in nodule_files[1:]:\n",
        "        tmp = np.load(nodule_file)\n",
        "        data = np.vstack((data, tmp))\n",
        "\t    \n",
        "    print(\"Number of patients:\", data.shape)\n",
        "    print(\"Patient shape:\", data[0][0].shape)\n",
        "    return data\n",
        "\n",
        "\n",
        "'''\n",
        "Trains a classifier to classify nodes as cancerous/non-cancerous\n",
        "'''\n",
        "def train_cancer_classifier():\n",
        "    data = load_cropped_nodules()\n",
        "\n",
        "    # Prepare data for training\n",
        "    nodules = data[0][0]\n",
        "    labels = np.ones(data[0][0].shape[0]) * data[0][2]\n",
        "    for idx, patient in enumerate(data[1:]):\n",
        "        if patient[0].any():\n",
        "            labels = np.concatenate((labels, np.ones(patient[0].shape[0]) * patient[2]))\n",
        "            nodules = np.vstack((nodules, patient[0]))\n",
        "\t    \n",
        "    print('Nodules shape:', nodules.shape)\n",
        "    print('Labels shape:', labels.shape)\n",
        "\n",
        "    num_classes = 2\n",
        "    num_samples = nodules.shape[0]\n",
        "    img_rows = nodules.shape[1]\n",
        "    img_cols = nodules.shape[2]\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(nodules, labels, test_size=0.33, random_state=42)\n",
        "\n",
        "    X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)\n",
        "    X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)\n",
        "    input_shape = (img_rows, img_cols, 1)\n",
        "\n",
        "    y_train = np_utils.to_categorical(y_train, num_classes)\n",
        "    y_test = np_utils.to_categorical(y_test, num_classes)        \n",
        "    print('Num train samples:', len(y_train))\n",
        "    print('Num test samples:', len(y_test))\n",
        "    \n",
        "    epochs = 50\n",
        "    batch_size = 128\n",
        "    model = get_conv2d_model()\n",
        "    print(X_train.shape)\n",
        "    print(y_train.shape)\n",
        "    model.fit(X_train, y_train, batch_size=batch_size, nb_epoch=epochs,\n",
        "                      verbose=2, validation_data=(X_test, y_test))\n",
        "    score = model.evaluate(X_test, y_test, verbose=0)\n",
        "    print('Test loss:', score[0])\n",
        "    print('Test accuracy:', score[1])\n",
        "\n",
        "    # save model\n",
        "    model.save_weights(lung_folder + 'convnet_nodules.h5')    \n",
        "\n",
        "def get_conv2d_model():\n",
        "    model = Sequential()\n",
        "    num_classes = 2\n",
        "    input_shape = (50, 50, 1)\n",
        "    model.add(Conv2D(32, 3, 3,\n",
        "\t\t     activation='relu',\n",
        "\t\t     input_shape=input_shape))\n",
        "\n",
        "    model.add(Conv2D(64, 3, 3, activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(128, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "    model.compile(loss='categorical_crossentropy',\n",
        "                  optimizer='adadelta',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "def classify_test_nodules():\n",
        "    img_rows, img_cols = (50, 50)\n",
        "    test_df = pd.read_csv('/content/drive/My Drive/lung/kaggle/stage1_sample_submission.csv')\n",
        "    test_nodules = np.load(lung_folder + 'test_cropped_heatmap_nodules_heat2_dice40.npy', allow_pickle=True)\n",
        "    model = get_conv2d_model()\n",
        "    model.load_weights(lung_folder + 'convnet_nodules.h5')\n",
        "        \n",
        "    for idx, patient in test_df[:1].iterrows():\n",
        "        test_nodules[idx][0] = test_nodules[idx][0].reshape((-1, img_rows, img_cols, 1))\n",
        "\n",
        "        if test_nodules[idx][0].shape[0] != 0:\n",
        "            prob = np.mean(model.predict(test_nodules[idx][0]), axis=0)[1]\n",
        "            test_df.loc[idx, 'cancer'] = prob\n",
        "        else:\n",
        "            test_df.loc[idx, 'cancer'] = 0.5        \n",
        "\n",
        "    test_df.head()\n",
        "    test_df.to_csv('./submission.csv')\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    #train_cancer_classifier()\n",
        "    classify_test_nodules()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-77275af6e2a7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[0;31m#train_cancer_classifier()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m     \u001b[0mclassify_test_nodules\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-7-77275af6e2a7>\u001b[0m in \u001b[0;36mclassify_test_nodules\u001b[0;34m()\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0mtest_nodules\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlung_folder\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'test_cropped_heatmap_nodules_heat2_dice40.npy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_pickle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_conv2d_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlung_folder\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'convnet_nodules.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatient\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(self, filepath, by_name, skip_mismatch, options)\u001b[0m\n\u001b[1;32m   2225\u001b[0m           'first, then load the weights.')\n\u001b[1;32m   2226\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assert_weights_created\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2227\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2228\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'layer_names'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m'model_weights'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2229\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_weights'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, **kwds)\u001b[0m\n\u001b[1;32m    406\u001b[0m                 fid = make_fid(name, mode, userblock_size,\n\u001b[1;32m    407\u001b[0m                                \u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmake_fcpl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 408\u001b[0;31m                                swmr=swmr)\n\u001b[0m\u001b[1;32m    409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlibver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m             \u001b[0mflags\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r+'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: Unable to open file (unable to open file: name = '/content/drive/MyDrive/lung/convnet_nodules.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K15CbYwul78i",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 387
        },
        "outputId": "8d8f549b-9ffe-4a3d-ed56-dab3e4602946"
      },
      "source": [
        "# resnet50\n",
        "# -*- coding: utf-8 -*-\n",
        "'''ResNet50 model for Keras.\n",
        "\n",
        "# Reference:\n",
        "\n",
        "- [Deep Residual Learning for Image Recognition](https://arxiv.org/abs/1512.03385)\n",
        "\n",
        "Adapted from code contributed by BigMoyan.\n",
        "'''\n",
        "from __future__ import print_function\n",
        "\n",
        "import numpy as np\n",
        "import warnings\n",
        "\n",
        "from keras.layers import merge, Input\n",
        "from keras.layers import Dense, Activation, Flatten\n",
        "from keras.layers import Convolution2D, MaxPooling2D, ZeroPadding2D, AveragePooling2D\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.models import Model\n",
        "from keras.preprocessing import image\n",
        "import keras.backend as K\n",
        "from keras.utils.layer_utils import convert_all_kernels_in_model\n",
        "from keras.utils.data_utils import get_file\n",
        "# from imagenet_utils import decode_predictions, preprocess_input\n",
        "\n",
        "\n",
        "TH_WEIGHTS_PATH = 'https://github.com/fchollet/deep-learning-models/releases/download/v0.2/resnet50_weights_th_dim_ordering_th_kernels.h5'\n",
        "TF_WEIGHTS_PATH = 'https://github.com/fchollet/deep-learning-models/releases/download/v0.2/resnet50_weights_tf_dim_ordering_tf_kernels.h5'\n",
        "TH_WEIGHTS_PATH_NO_TOP = 'https://github.com/fchollet/deep-learning-models/releases/download/v0.2/resnet50_weights_th_dim_ordering_th_kernels_notop.h5'\n",
        "TF_WEIGHTS_PATH_NO_TOP = 'https://github.com/fchollet/deep-learning-models/releases/download/v0.2/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
        "\n",
        "\n",
        "def identity_block(input_tensor, kernel_size, filters, stage, block):\n",
        "    '''The identity_block is the block that has no conv layer at shortcut\n",
        "\n",
        "    # Arguments\n",
        "        input_tensor: input tensor\n",
        "        kernel_size: defualt 3, the kernel size of middle conv layer at main path\n",
        "        filters: list of integers, the nb_filters of 3 conv layer at main path\n",
        "        stage: integer, current stage label, used for generating layer names\n",
        "        block: 'a','b'..., current block label, used for generating layer names\n",
        "    '''\n",
        "    nb_filter1, nb_filter2, nb_filter3 = filters\n",
        "    if K.set_image_data_format('channels_first'):\n",
        "        bn_axis = 3\n",
        "    else:\n",
        "        bn_axis = 1\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "\n",
        "    x = Convolution2D(nb_filter1, 1, 1, name=conv_name_base + '2a')(input_tensor)\n",
        "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2a')(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = Convolution2D(nb_filter2, kernel_size, kernel_size,\n",
        "                      border_mode='same', name=conv_name_base + '2b')(x)\n",
        "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2b')(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = Convolution2D(nb_filter3, 1, 1, name=conv_name_base + '2c')(x)\n",
        "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2c')(x)\n",
        "\n",
        "    x = merge([x, input_tensor], mode='sum')\n",
        "    x = Activation('relu')(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "def conv_block(input_tensor, kernel_size, filters, stage, block, strides=(2, 2)):\n",
        "    '''conv_block is the block that has a conv layer at shortcut\n",
        "\n",
        "    # Arguments\n",
        "        input_tensor: input tensor\n",
        "        kernel_size: defualt 3, the kernel size of middle conv layer at main path\n",
        "        filters: list of integers, the nb_filters of 3 conv layer at main path\n",
        "        stage: integer, current stage label, used for generating layer names\n",
        "        block: 'a','b'..., current block label, used for generating layer names\n",
        "\n",
        "    Note that from stage 3, the first conv layer at main path is with subsample=(2,2)\n",
        "    And the shortcut should have subsample=(2,2) as well\n",
        "    '''\n",
        "    nb_filter1, nb_filter2, nb_filter3 = filters\n",
        "    if K.image_dim_ordering() == 'tf':\n",
        "        bn_axis = 3\n",
        "    else:\n",
        "        bn_axis = 1\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "\n",
        "    x = Convolution2D(nb_filter1, 1, 1, subsample=strides,\n",
        "                      name=conv_name_base + '2a')(input_tensor)\n",
        "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2a')(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = Convolution2D(nb_filter2, kernel_size, kernel_size, border_mode='same',\n",
        "                      name=conv_name_base + '2b')(x)\n",
        "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2b')(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = Convolution2D(nb_filter3, 1, 1, name=conv_name_base + '2c')(x)\n",
        "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2c')(x)\n",
        "\n",
        "    shortcut = Convolution2D(nb_filter3, 1, 1, subsample=strides,\n",
        "                             name=conv_name_base + '1')(input_tensor)\n",
        "    shortcut = BatchNormalization(axis=bn_axis, name=bn_name_base + '1')(shortcut)\n",
        "\n",
        "    x = merge([x, shortcut], mode='sum')\n",
        "    x = Activation('relu')(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "def ResNet50(include_top=True, weights='imagenet',\n",
        "             input_tensor=None):\n",
        "    '''Instantiate the ResNet50 architecture,\n",
        "    optionally loading weights pre-trained\n",
        "    on ImageNet. Note that when using TensorFlow,\n",
        "    for best performance you should set\n",
        "    `image_dim_ordering=\"tf\"` in your Keras config\n",
        "    at ~/.keras/keras.json.\n",
        "\n",
        "    The model and the weights are compatible with both\n",
        "    TensorFlow and Theano. The dimension ordering\n",
        "    convention used by the model is the one\n",
        "    specified in your Keras config file.\n",
        "\n",
        "    # Arguments\n",
        "        include_top: whether to include the 3 fully-connected\n",
        "            layers at the top of the network.\n",
        "        weights: one of `None` (random initialization)\n",
        "            or \"imagenet\" (pre-training on ImageNet).\n",
        "        input_tensor: optional Keras tensor (i.e. xput of `layers.Input()`)\n",
        "            to use as image input for the model.\n",
        "\n",
        "    # Returns\n",
        "        A Keras model instance.\n",
        "    '''\n",
        "    if weights not in {'imagenet', None}:\n",
        "        raise ValueError('The `weights` argument should be either '\n",
        "                         '`None` (random initialization) or `imagenet` '\n",
        "                         '(pre-training on ImageNet).')\n",
        "    # Determine proper input shape\n",
        "    if K.set_image_data_format('channels_first'):\n",
        "        if include_top:\n",
        "            input_shape = (3, 224, 224)\n",
        "        else:\n",
        "            input_shape = (3, None, None)\n",
        "    else:\n",
        "        if include_top:\n",
        "            input_shape = (224, 224, 3)\n",
        "        else:\n",
        "            input_shape = (None, None, 3)\n",
        "\n",
        "    if input_tensor is None:\n",
        "        img_input = Input(shape=input_shape)\n",
        "    else:\n",
        "        if not K.is_keras_tensor(input_tensor):\n",
        "            img_input = Input(tensor=input_tensor)\n",
        "        else:\n",
        "            img_input = input_tensor\n",
        "    if K.set_image_data_format('channels_first'):\n",
        "        bn_axis = 3\n",
        "    else:\n",
        "        bn_axis = 1\n",
        "\n",
        "    x = ZeroPadding2D((3, 3))(img_input)\n",
        "    x = Convolution2D(64, 7, 7, subsample=(2, 2), name='conv1')(x)\n",
        "    x = BatchNormalization(axis=bn_axis, name='bn_conv1')(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
        "\n",
        "    x = conv_block(x, 3, [64, 64, 256], stage=2, block='a', strides=(1, 1))\n",
        "    x = identity_block(x, 3, [64, 64, 256], stage=2, block='b')\n",
        "    x = identity_block(x, 3, [64, 64, 256], stage=2, block='c')\n",
        "\n",
        "    x = conv_block(x, 3, [128, 128, 512], stage=3, block='a')\n",
        "    x = identity_block(x, 3, [128, 128, 512], stage=3, block='b')\n",
        "    x = identity_block(x, 3, [128, 128, 512], stage=3, block='c')\n",
        "    x = identity_block(x, 3, [128, 128, 512], stage=3, block='d')\n",
        "\n",
        "    x = conv_block(x, 3, [256, 256, 1024], stage=4, block='a')\n",
        "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='b')\n",
        "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='c')\n",
        "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='d')\n",
        "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='e')\n",
        "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='f')\n",
        "\n",
        "    x = conv_block(x, 3, [512, 512, 2048], stage=5, block='a')\n",
        "    x = identity_block(x, 3, [512, 512, 2048], stage=5, block='b')\n",
        "    x = identity_block(x, 3, [512, 512, 2048], stage=5, block='c')\n",
        "\n",
        "    x = AveragePooling2D((7, 7), name='avg_pool')(x)\n",
        "\n",
        "    if include_top:\n",
        "        x = Flatten()(x)\n",
        "        x = Dense(1000, activation='softmax', name='fc1000')(x)\n",
        "\n",
        "    model = Model(img_input, x)\n",
        "\n",
        "    # load weights\n",
        "    if weights == 'imagenet':\n",
        "        print('K.image_dim_ordering:', K.image_dim_ordering())\n",
        "        if K.set_image_data_format('channels_first'):\n",
        "            if include_top:\n",
        "                weights_path = get_file('resnet50_weights_th_dim_ordering_th_kernels.h5',\n",
        "                                        TH_WEIGHTS_PATH,\n",
        "                                        cache_subdir='models',\n",
        "                                        md5_hash='1c1f8f5b0c8ee28fe9d950625a230e1c')\n",
        "            else:\n",
        "                weights_path = get_file('resnet50_weights_th_dim_ordering_th_kernels_notop.h5',\n",
        "                                        TH_WEIGHTS_PATH_NO_TOP,\n",
        "                                        cache_subdir='models',\n",
        "                                        md5_hash='f64f049c92468c9affcd44b0976cdafe')\n",
        "            model.load_weights(weights_path)\n",
        "            if K.backend() == 'tensorflow':\n",
        "                warnings.warn('You are using the TensorFlow backend, yet you '\n",
        "                              'are using the Theano '\n",
        "                              'image dimension ordering convention '\n",
        "                              '(`image_dim_ordering=\"th\"`). '\n",
        "                              'For best performance, set '\n",
        "                              '`image_dim_ordering=\"tf\"` in '\n",
        "                              'your Keras config '\n",
        "                              'at ~/.keras/keras.json.')\n",
        "                convert_all_kernels_in_model(model)\n",
        "        else:\n",
        "            if include_top:\n",
        "                weights_path = get_file('resnet50_weights_tf_dim_ordering_tf_kernels.h5',\n",
        "                                        TF_WEIGHTS_PATH,\n",
        "                                        cache_subdir='models',\n",
        "                                        md5_hash='a7b3fe01876f51b976af0dea6bc144eb')\n",
        "            else:\n",
        "                weights_path = get_file('resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5',\n",
        "                                        TF_WEIGHTS_PATH_NO_TOP,\n",
        "                                        cache_subdir='models',\n",
        "                                        md5_hash='a268eb855778b3df3c7506639542a6af')\n",
        "            model.load_weights(weights_path)\n",
        "            if K.backend() == 'theano':\n",
        "                convert_all_kernels_in_model(model)\n",
        "    return model\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    model = ResNet50(include_top=True, weights='imagenet')\n",
        "\n",
        "    img_path = 'elephant.jpg'\n",
        "    img = image.load_img(img_path, target_size=(224, 224))\n",
        "    x = image.img_to_array(img)\n",
        "    x = np.expand_dims(x, axis=0)\n",
        "    x = preprocess_input(x)\n",
        "    print('Input image shape:', x.shape)\n",
        "\n",
        "    preds = model.predict(x)\n",
        "    print('Predicted:', decode_predictions(preds))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-cf7ba9a144f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mResNet50\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minclude_top\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'imagenet'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m     \u001b[0mimg_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'elephant.jpg'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-34-cf7ba9a144f7>\u001b[0m in \u001b[0;36mResNet50\u001b[0;34m(include_top, weights, input_tensor)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mZeroPadding2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConvolution2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubsample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'conv1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchNormalization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbn_axis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'bn_conv1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mActivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/convolutional.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filters, kernel_size, strides, padding, data_format, dilation_rate, groups, activation, use_bias, kernel_initializer, bias_initializer, kernel_regularizer, bias_regularizer, activity_regularizer, kernel_constraint, bias_constraint, **kwargs)\u001b[0m\n\u001b[1;32m    669\u001b[0m         \u001b[0mkernel_constraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconstraints\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkernel_constraint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m         \u001b[0mbias_constraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconstraints\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_constraint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 671\u001b[0;31m         **kwargs)\n\u001b[0m\u001b[1;32m    672\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/convolutional.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, rank, filters, kernel_size, strides, padding, data_format, dilation_rate, groups, activation, use_bias, kernel_initializer, bias_initializer, kernel_regularizer, bias_regularizer, activity_regularizer, kernel_constraint, bias_constraint, trainable, name, conv_op, **kwargs)\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0mactivity_regularizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mregularizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactivity_regularizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m         **kwargs)\n\u001b[0m\u001b[1;32m    139\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrank\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrank\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    515\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, trainable, name, dtype, dynamic, **kwargs)\u001b[0m\n\u001b[1;32m    338\u001b[0m     }\n\u001b[1;32m    339\u001b[0m     \u001b[0;31m# Validate optional keyword arguments.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 340\u001b[0;31m     \u001b[0mgeneric_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallowed_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m     \u001b[0;31m# Mutable properties\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mvalidate_kwargs\u001b[0;34m(kwargs, allowed_kwargs, error_message)\u001b[0m\n\u001b[1;32m    806\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mkwarg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    807\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mkwarg\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mallowed_kwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 808\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_message\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwarg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    809\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: ('Keyword argument not understood:', 'subsample')"
          ]
        }
      ]
    }
  ]
}